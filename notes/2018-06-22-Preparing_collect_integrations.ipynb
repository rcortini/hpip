{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, gzip\n",
    "import hpiptools as ht\n",
    "import mybiotools as mbt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-06-21 Preparing \"collect_integrations\"\n",
    "\n",
    "In this notebook I want to prepare the final part of the pipeline, which consists in two separate steps:\n",
    "\n",
    "1. Collect the mapping and counting information from each library. This is an easy step, in which I only need to parse relatively easy files.\n",
    "2. Assign a promoter to each barcode. This is the difficult step. To do this, I need to harness all the information that I have, which currently is:\n",
    "    - what does the promoter-barcode dictionary says\n",
    "    - what iPCR, cDNA, and gDNA index say\n",
    "\n",
    "The latter step is the most complicated, because potentially the first assignment of the read to a particular library, based on the index, were not done correctly. Therefore, I want to store all the information that I possibly have into a data structure that will allow to have an idea of how to assign the promoter in the best possible way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPIP root directory\n",
    "hpip_root = '%s/work/CRG/projects/hpip'%(os.getenv('HOME'))\n",
    "\n",
    "# prepare the names of the libraries\n",
    "libs = ['lib%d'%(i) for i in range(2, 13)]\n",
    "libs.append('undetermined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Replicate :\n",
    "    def __init__(self, rep_name) :\n",
    "        self.rep_name = rep_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_names = ['rep1', 'rep2']\n",
    "reps = []\n",
    "for rep_name in rep_names :\n",
    "    reps.append(Replicate(rep_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rep in reps :\n",
    "    # now we parse ALL the starcoded cDNA and gDNA output files\n",
    "    cDNA_canonicals = {}\n",
    "    cDNA_counts = {}\n",
    "    gDNA_canonicals = {}\n",
    "    gDNA_counts = {}\n",
    "    for lib in libs :\n",
    "        libdir = '%s/data/triplibs/%s/%s'%(hpip_root, rep.rep_name, lib)\n",
    "        cDNA_starcode_fname = '%s/cDNA-starcode.txt'%(libdir)\n",
    "        gDNA_starcode_fname = '%s/gDNA-starcode.txt'%(libdir)\n",
    "        if not os.path.exists(cDNA_starcode_fname) or\\\n",
    "           not os.path.exists(gDNA_starcode_fname) :\n",
    "                continue\n",
    "        ht.log_message(rep.rep_name, 'Parsing %s starcode'%(lib))\n",
    "        cDNA_canonicals[lib], cDNA_counts[lib] =\\\n",
    "                   ht.parse_starcode(cDNA_starcode_fname)\n",
    "        gDNA_canonicals[lib], gDNA_counts[lib] =\\\n",
    "                   ht.parse_starcode(gDNA_starcode_fname)\n",
    "    \n",
    "    # assign the structure to the replicate\n",
    "    rep.cDNA_canonicals = cDNA_canonicals\n",
    "    rep.cDNA_counts = cDNA_counts\n",
    "    rep.gDNA_canonicals = gDNA_canonicals\n",
    "    rep.gDNA_counts = gDNA_counts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rep in reps :\n",
    "    iPCR_canonicals = {}\n",
    "    iPCR_counts = {}\n",
    "    mapped = {}\n",
    "    for lib in libs :\n",
    "        # data directory for the library under study\n",
    "        lib_dir = '%s/data/triplibs/%s/%s'%(hpip_root, rep.rep_name, lib)\n",
    "\n",
    "        # build file names\n",
    "        iPCR_starcode_fname = '%s/iPCR-starcode.txt'%(lib_dir)\n",
    "        iPCR_sam_fname = '%s/iPCR.sam'%(lib_dir)\n",
    "\n",
    "        # work on the starcoded files\n",
    "        ht.log_message(rep.rep_name, 'Processing %s iPCR starcode'%(lib))\n",
    "        iPCR_canonicals[lib], iPCR_counts[lib] =\\\n",
    "                  ht.parse_starcode(iPCR_starcode_fname)\n",
    "            \n",
    "        # now we can open the mapped file\n",
    "        ht.log_message(rep.rep_name, 'Processing %s mapped file'%(lib))\n",
    "        mapped[lib], nmulti, nmapped, nunmapped =\\\n",
    "             ht.parse_mapped(iPCR_sam_fname)\n",
    "    rep.iPCR_canonicals = iPCR_canonicals\n",
    "    rep.iPCR_counts = iPCR_counts\n",
    "    rep.mapped = mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlibs = len(libs)\n",
    "for rep in reps :\n",
    "    \n",
    "    rep.cDNA_transitions = np.zeros((nlibs, nlibs), dtype=np.int32)\n",
    "    rep.gDNA_transitions = np.zeros((nlibs, nlibs), dtype=np.int32)\n",
    "    \n",
    "    # go through all the libraries\n",
    "    for i, lib_origin in enumerate(libs) :\n",
    "        \n",
    "        ht.log_message(rep.rep_name, 'Processing %s'%(lib_origin))\n",
    "        \n",
    "        # go through all the integrations in that library\n",
    "        for bcd, integration in rep.mapped[lib_origin].iteritems() :\n",
    "            try :\n",
    "                canonical = rep.iPCR_canonicals[lib_origin][bcd]\n",
    "            except KeyError :\n",
    "                # this occurs if a barcode was removed from the output\n",
    "                # sequences of starcode because of ambiguous cluster \n",
    "                # assignment.\n",
    "                continue\n",
    "\n",
    "            # now we try to find a match between the canonical and the cDNA\n",
    "            # and gDNA canonicals in ALL other libraries\n",
    "            for j, lib in enumerate(libs) :\n",
    "                if rep.cDNA_canonicals[lib].has_key(canonical) :\n",
    "                    rep.cDNA_transitions[i,j] += 1\n",
    "                if rep.gDNA_canonicals[lib].has_key(canonical) :\n",
    "                    rep.gDNA_transitions[i,j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure preparation\n",
    "labels = [s[:5] for s in libs]\n",
    "for rep in reps :\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(8, 16))\n",
    "    x = range(len(libs))\n",
    "\n",
    "    # cDNA\n",
    "    ax = axes[0]\n",
    "    ax.matshow(mbt.row_normalize_matrix(rep.cDNA_transitions.astype('float')))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, rotation=90)\n",
    "    ax.set_yticks(x)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_ylabel('cDNA')\n",
    "    ax.set_title(rep.rep_name, y=1.1, fontsize=32)\n",
    "\n",
    "    # gDNA\n",
    "    ax = axes[1]\n",
    "    ax.matshow(mbt.row_normalize_matrix(rep.gDNA_transitions.astype('float')))\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, rotation=90)\n",
    "    ax.set_yticks(x)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_ylabel('gDNA')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning the promoter to each integration\n",
    "\n",
    "Now that all of this is done, it's more clear what's going on. There's a part which is the easy part: replicate 1. In replicate 2, there's more work to do to assign the library index correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init promoter-barcode dictionary\n",
    "pbd = ht.PBD(hpip_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom_libs = range(1,13)\n",
    "prom_lib_idx = {str(prom_lib) : prom_lib-1 for prom_lib in prom_libs}\n",
    "prom_class_idx = {'A':0,'B':1,'C':2,'D':3,\n",
    "              'E':4,'F':5,'G':6,'H':7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoters = np.zeros((8,12))\n",
    "n = 0\n",
    "mapped = reps[0].mapped['lib3']\n",
    "for bcd in mapped.iterkeys() :\n",
    "    n += 1\n",
    "    candidates = pbd.findbcd(bcd)\n",
    "    if candidates is None :\n",
    "        continue\n",
    "    candidates = ht.parse_bcd(candidates)\n",
    "    for candidate in candidates.iterkeys() :\n",
    "        prom_class, prom_lib = ht.prom_id(candidate)\n",
    "        promoters[prom_class_idx[prom_class], prom_lib_idx[prom_lib]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cax = plt.matshow(np.log10(promoters+1))\n",
    "plt.xticks(prom_lib_idx.values(), prom_lib_idx.keys())\n",
    "plt.yticks(prom_class_idx.values(), prom_class_idx.keys())\n",
    "plt.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(12), np.log10(promoters.sum(axis=0)))\n",
    "plt.xticks(prom_lib_idx.values(), prom_lib_idx.keys())\n",
    "plt.xlabel('Library ID')\n",
    "plt.ylabel('Log_10 Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works well in some cases, much less so in other cases. What we now need to do is to find a way of assigning a barcode to a promoter, based on all the information we collected so far. A first preparatory step for this process is to merge all the integrations into one, if they have the same integration site. Let's have a look at the distribution of counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = reps[1]\n",
    "lib = 'lib7'\n",
    "ninsertions = []\n",
    "for bcd, insertion in rep.mapped[lib].iteritems() :\n",
    "    if rep.cDNA_counts[lib].has_key(bcd) and\\\n",
    "       rep.gDNA_counts[lib].has_key(bcd) :\n",
    "        ninsertions.append(insertion[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "ax.hist(ninsertions,bins=100)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Number of integrations')\n",
    "ax.set_ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fine, the number of integrations has a kind of expected decay. Now I prepare the functions that will allow me to sanitize the barcode list, before finally writing the output to the final files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = reps[1]\n",
    "lib_id = 7\n",
    "lib = 'lib%d'%(lib_id)\n",
    "n = 0\n",
    "with open('test.txt', 'w') as f :\n",
    "    for bcd, insertion in rep.mapped[lib].iteritems() :\n",
    "        \n",
    "        # define flags that will allow us to make some statistics\n",
    "        # about how many integration get in and out of the final\n",
    "        # insertion table\n",
    "        in_cDNA = rep.cDNA_counts[lib].has_key(bcd)\n",
    "        in_gDNA = rep.gDNA_counts[lib].has_key(bcd)\n",
    "        in_both = in_cDNA and in_gDNA\n",
    "        \n",
    "        # interrogate the pbd to know whether the barcode that we\n",
    "        # are looking at was actually known in the promoter-barcode\n",
    "        # association table\n",
    "        pr = pbd.findbcd(bcd)\n",
    "        in_pbd = pr is not None\n",
    "        \n",
    "        # proceed with the calculations only if the three conditions\n",
    "        # are met: the mapped insertion is in the cDNA, in the gDNA, \n",
    "        # and in the pbd.\n",
    "        if in_cDNA and in_gDNA and in_pbd :\n",
    "            n += 1\n",
    "            \n",
    "            # get the list of promoters associated to the\n",
    "            # barcode from the pbd\n",
    "            proms = ht.parse_bcd(pr)\n",
    "            in_pbd_lib = proms.has_key(lib_id)\n",
    "            \n",
    "            # if we find that the barcode was in the pbd, but none of\n",
    "            # the candidate promoters are in the library under consideration,\n",
    "            # then we need to throw this integration away because we cannot\n",
    "            # know which promoter it is associated to\n",
    "            if not in_pbd_lib :\n",
    "                continue\n",
    "\n",
    "            # if we are here, everything is fine and we prepare the string\n",
    "            # that we output to our final file. First, we prepare a string\n",
    "            # that contains the information about the candidate promoters\n",
    "            prom_string = ''\n",
    "            for prom_class, p in proms[lib_id] :\n",
    "                prom_string += '\\t%s%d:%s'%(prom_class, lib_id, p)\n",
    "            \n",
    "            # we then prepare the line that contains the information about\n",
    "            # the barcode, the mapping, the reads, and the promoter\n",
    "            chrom, pos, strand = insertion[0]\n",
    "            iPCR_counts = insertion[1]\n",
    "            line = '%s\\t'%(bcd)\n",
    "            line += '%s\\t%d\\t%s'%(chrom, pos, strand)\n",
    "            line += '\\t%d\\t%d\\t%d'%(iPCR_counts,\n",
    "                                   rep.cDNA_counts[lib][bcd],\n",
    "                                   rep.gDNA_counts[lib][bcd])\n",
    "            line += prom_string\n",
    "            line += '\\n'\n",
    "            f.write(line)\n",
    "            # print line\n",
    "        # if n>=10 : break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with this, we're ready to write the collect_integrations script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import hpiptools as ht\n",
    "from numpy.lib.recfunctions import append_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-05-15 Post processing pipeline\n",
    "After the very first preliminary analysis of the output of the HPIP pipeline, I want to move on to another basic question. That is: are there any very specific patterns that are already evident in how the promoters behave, as a function of the promoter class? To do this analysis, first I need to get a way of analysing the promoter classes. That's to say: how do I map \"H5\" to the promoter patterns? I need to dig into the files that Marc produced to figure this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"mc_\" stands for \"Marc Corrales\"\n",
    "mc_hpip_root_dir = '/mnt/ant-login/mcorrales/HPIP'\n",
    "promoter_table_fname = '%s/Doc/Dockerdata_hpip/hpip/100_sampled_proms.tsv'%(mc_hpip_root_dir)\n",
    "# let's parse this file\n",
    "promoter_table_dtype = [\n",
    "    ('chr','S4'),\n",
    "    ('start',np.int32),\n",
    "    ('end',np.int32),\n",
    "    ('strand','S2'),\n",
    "]\n",
    "for i in xrange(ht.nclasses) :\n",
    "    promoter_table_dtype.append(('class_%d'%(i+1),np.int32))\n",
    "promoter_table_dtype.append(('color','S16'))\n",
    "promoter_table_dtype.append(('class',np.int32))\n",
    "promoter_table = np.genfromtxt(promoter_table_fname,dtype=promoter_table_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I very quickly realize that answering any of the interesting questions will require putting the data into a data structure that is much more convenient than the \"HPIPMatrix\" that I defined in the previous notebook. The problem is that the mapping of the promoter name assigned in the \"integrations\" file is not obviously related to the number of promoter and its class as defined in the \"promoter_table\" that I just parsed. The results will be very difficult to analyze if we provide an intermediate structure that does the mapping between the two names. It is therefore more sensible to start developing a pipeline that does the post-processing analysis of the data, so that the analysis will later be much easier.\n",
    "\n",
    "## Structure of the post-processing pipeline\n",
    "\n",
    "1. **GET**: parse the results of the HPIP pipeline\n",
    "2. **NAME**: restore the original name of the promoters, which will allow to get its class with a simple arithmetic operation\n",
    "3. **FILTER**: remove reads that map to weird chromosomes, remove collision barcodes\n",
    "4. **SORT**: put all of these reads in order, by promoter and by chromosome\n",
    "5. **NORMALIZE**: use the spikes and other magic to normalize the expression of the integration by the number of reads in the gDNA and so on.\n",
    "\n",
    "I can start writing a procedural code to do this, wondering whether it will be sensible in the future to write it object-oriented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_name_insertion(insertion,\n",
    "                          chromosome_list=['2L','2R','3L','3R','4','X','Y']) :\n",
    "    p = insertion['promoter']\n",
    "    if p == 'Colision' :\n",
    "        return None\n",
    "    else :\n",
    "        if insertion['chr'] not in chromosome_list :\n",
    "            return None\n",
    "        else :\n",
    "            insertion['promoter'] = ht.plate_to_prom[p]\n",
    "            return insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE\n",
    "def normalize_insertions(insertions) :\n",
    "    # we first get the sum of all the reads of mRNA and gDNA, per replicate\n",
    "    reps = np.unique(insertions['rep'])\n",
    "    mRNA_sum = {}\n",
    "    gDNA_sum = {}\n",
    "    for rep in reps :\n",
    "        # get replicate-specific insertions\n",
    "        rep_mask = insertions['rep']==rep\n",
    "        # get sum of mRNA, sum of gDNA, and average mRNA of the replicate\n",
    "        mRNA_sum[rep] = insertions[rep_mask]['mRNA'].sum()\n",
    "        gDNA_sum[rep] = insertions[rep_mask]['gDNA'].sum()\n",
    "    # then we initialize the \"normalized\" array, and fill it with the stuff\n",
    "    # that was already contained in the passed array\n",
    "    normalized_dtype = [\n",
    "        ('barcode','S32'),\n",
    "        ('chr','S4'),\n",
    "        ('coord',np.int32),\n",
    "        ('strand','S2'),\n",
    "        ('promoter',np.int32),\n",
    "        ('rep','S8'),\n",
    "        ('expression',float)\n",
    "    ]\n",
    "    normalized = np.zeros(insertions.size,dtype=np.dtype(normalized_dtype))\n",
    "    keep = ['barcode','chr','coord','strand','promoter','rep']\n",
    "    for param in keep :\n",
    "        normalized[param] = insertions[param]\n",
    "    # finally, we normalize the expression\n",
    "    nan_mask = insertions['gDNA'] == 0\n",
    "    # insertions with zero gDNA counts have NAN expression\n",
    "    expression = np.zeros(insertions.size)\n",
    "    expression[nan_mask] = np.nan\n",
    "    # the others, we do log(eps/<eps>), specific for each replicate, where\n",
    "    # eps = (mRNA/mRNA_sum)/(gDNA/gDNA_sum)\n",
    "    for rep in reps :\n",
    "        rep_mask = insertions['rep']==rep\n",
    "        mask = np.logical_and(~nan_mask,rep_mask)\n",
    "        eps = (insertions[mask]['mRNA']/float(mRNA_sum[rep]))/\\\n",
    "              (insertions[mask]['gDNA']/float(gDNA_sum[rep]))\n",
    "        eps_mean = eps.mean()\n",
    "        expression[mask] = np.log2(eps/eps_mean)\n",
    "    normalized['expression'] = expression\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET\n",
    "hpip_root_dir = '%s/work/CRG/projects/hpip'%(os.getenv('HOME'))\n",
    "production_dir = '%s/production'%(hpip_root_dir)\n",
    "reps = []\n",
    "for rep_name in ['rep1','rep2'] :\n",
    "    rep_fname = '%s/%s/HPIP_iPCR_%s_insertions.txt'%(production_dir,rep_name,rep_name)\n",
    "    rep = ht.load_hpip_results(rep_fname,rep_name)\n",
    "    reps.append(rep)\n",
    "    \n",
    "# MERGE\n",
    "merged = np.concatenate([r for r in reps])\n",
    "\n",
    "# SORT\n",
    "merged.sort(order=['chr','coord'])\n",
    "\n",
    "# FILTER AND NAME\n",
    "filtered = []\n",
    "for insertion in merged :\n",
    "    f = filter_and_name_insertion(insertion)\n",
    "    if f is not None :\n",
    "        filtered.append(f)\n",
    "filtered = np.array(filtered)        \n",
    "# no need of storing the intermediate structure\n",
    "del merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = normalize_insertions(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works. What remains to do is to decide what to do with insertions that have zero gDNA counts. I'll now translate all this code to a separate file that will then work to do all of this reproducibly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a plain, democratic text file\n",
    "out_fname = '%s/HPIP_results.txt'%(production_dir)\n",
    "with open(out_fname, 'w') as f :\n",
    "    f.write('# barcode chromosome strand coordinate promoter replicate expression\\n')\n",
    "    for insertion in normalized :\n",
    "        f.write('%s\\t%s\\t%s\\t%d\\t%s\\t%s\\t%f\\n'%(\n",
    "            insertion['barcode'],\n",
    "            insertion['chr'],\n",
    "            insertion['strand'],\n",
    "            insertion['coord'],\n",
    "            insertion['promoter'],\n",
    "            insertion['rep'],\n",
    "            insertion['expression']\n",
    "        ))\n",
    "\n",
    "# and a npy file for the Python enthusiasts\n",
    "out_fname = '%s/HPIP_results.npy'%(production_dir)\n",
    "np.save(out_fname,normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_dtype = [\n",
    "    ('x','S2'),\n",
    "    ('y',float)\n",
    "]\n",
    "N = 10\n",
    "A = np.zeros(N,dtype=mock_dtype)\n",
    "A['y'] = 10\n",
    "print A\n",
    "np.random.seed(1233)\n",
    "mask = np.random.randint(2,size=N).astype(bool)\n",
    "print mask\n",
    "A[mask]['y'] = 3\n",
    "print A\n",
    "y = np.zeros(N)\n",
    "y[mask] = 3\n",
    "print y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

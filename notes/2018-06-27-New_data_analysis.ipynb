{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mybiotools as mbt\n",
    "import hpiptools as ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-06-27 New data analysis\n",
    "\n",
    "We now have a complete list of barcodes that we can trust that were really good integrations. Let's have a quick look at some basic aspects of the integrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "hpip_root = '/home/rcortini/work/CRG/projects/hpip'\n",
    "hpip_integrations_fname = '%s/data/hpip-integrations.txt'%(hpip_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first: now we have a list of promoters that are possible candidates for each barcode. Let's write a parser of the file that takes this into account. First, let's see how the number of retrieved barcodes varies as a function of how strict we are with promoter assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hpip_integrations(fname, tol) :\n",
    "    \"\"\"\n",
    "    Load the HPIP integrations file `fname`. For each of the barcodes,\n",
    "    we accept only the promoter that has a probability of being called\n",
    "    greater than `tol`. If none passes the test, then we throw the barcode\n",
    "    away.\n",
    "    \"\"\"\n",
    "    hpip_dtype = [\n",
    "        ('barcode','S32'),\n",
    "        ('chr','S32'),\n",
    "        ('pos',np.int32),\n",
    "        ('strand','S2'),\n",
    "        ('iPCR',np.int32),\n",
    "        ('cDNA',np.int32),\n",
    "        ('gDNA',np.int32),\n",
    "        ('lib','S8'),\n",
    "        ('rep','S8'),\n",
    "        ('promoter','S32'),\n",
    "        ('p',np.float32)\n",
    "    ]\n",
    "    with open(fname, 'r') as f :\n",
    "        bcds = []\n",
    "        for line in f :\n",
    "            curatedline = line.strip('\\n').split('\\t')\n",
    "            bcd, chrom, pos, strand, \\\n",
    "            lib, rep, iPCR, cDNA, gDNA = curatedline[:9]\n",
    "            proms_raw = curatedline[9:]\n",
    "            f = lambda x : float(x.split(':')[1])\n",
    "            ps = [f(p) for p in proms_raw]\n",
    "            maxp = max(ps)\n",
    "            if maxp < tol :\n",
    "                continue\n",
    "            else :\n",
    "                imax = ps.index(maxp)\n",
    "            prom, p = proms_raw[imax].split(':')\n",
    "            bcds.append((bcd, chrom, pos, strand, iPCR, cDNA, gDNA, lib, rep, prom, p))\n",
    "    return np.array(bcds, dtype=np.dtype(hpip_dtype))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now let's see how the number of integrations varies as a function of the tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tols = np.arange(0.,1.05,0.05)\n",
    "size_tols = np.zeros(tols.size)\n",
    "for i, tol in enumerate(tols) :\n",
    "    hpip = load_hpip_integrations(hpip_integrations_fname, tol)\n",
    "    size_tols[i] = hpip.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tols, size_tols, linewidth=3)\n",
    "plt.xlabel('Tolerance')\n",
    "plt.ylabel('Number of integrations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay this is the kind of expected behaviour. There are a lot of integrations that are thrown away between 80% and 100% of tolerance. Let's choose 90% tolerance as a measure, for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 0.9\n",
    "hpip = load_hpip_integrations(hpip_integrations_fname, tol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now ask another basic question: how many integrations do we have per promoter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom_libs = range(1,13)\n",
    "prom_lib_idx = {str(prom_lib) : prom_lib-1 for prom_lib in prom_libs}\n",
    "prom_class_idx = {'A':0,'B':1,'C':2,'D':3,\n",
    "              'E':4,'F':5,'G':6,'H':7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoters = np.zeros((8,12))\n",
    "for integration in hpip :\n",
    "    prom_class, prom_lib = ht.prom_id(integration['promoter'])\n",
    "    promoters[prom_class_idx[prom_class], prom_lib_idx[prom_lib]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cax = plt.matshow(np.log10(promoters+1), cmap=plt.cm.Greens)\n",
    "plt.xticks(prom_lib_idx.values(), prom_lib_idx.keys())\n",
    "plt.yticks(prom_class_idx.values(), prom_class_idx.keys())\n",
    "plt.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate the results by replicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = np.unique(hpip['rep'])\n",
    "hpip_rep = {}\n",
    "for rep in reps :\n",
    "    hpip_rep[rep] = np.array([i for i in hpip if i['rep']==rep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoters_rep = {}\n",
    "for rep in reps :\n",
    "    promoters_rep[rep] = np.zeros((8,12))\n",
    "    for integration in hpip_rep[rep] :\n",
    "        prom_class, prom_lib = ht.prom_id(integration['promoter'])\n",
    "        promoters_rep[rep][prom_class_idx[prom_class], prom_lib_idx[prom_lib]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rep in reps :\n",
    "    cax = plt.matshow(np.log10(promoters_rep[rep]+1), cmap=plt.cm.Greens)\n",
    "    plt.xticks(prom_lib_idx.values(), prom_lib_idx.keys())\n",
    "    plt.yticks(prom_class_idx.values(), prom_class_idx.keys())\n",
    "    cbar = plt.colorbar(cax)\n",
    "    plt.title(rep, y=1.1, fontsize=32)\n",
    "    cbar.set_label(\"Log_10 counts\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this is the stop signal. The numbers are insufficient to do anything else."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
